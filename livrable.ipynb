{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583e36aa",
   "metadata": {},
   "source": [
    "# Projet SDP : Explications de classements par Trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08380cf",
   "metadata": {},
   "source": [
    "**Membres du groupe** : Adham Noureldin, Aymane Chalh, Daphné Maschas\n",
    "\n",
    "**Date** : 19 Janvier 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "import pandas as pd\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373209c2",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948ac38",
   "metadata": {},
   "source": [
    "Ce projet vise à fournir des explications intelligibles pour le classement des candidats au concours de l'internat de médecine. Au lieu d'utiliser la somme pondérée brute, nous justifions qu'un candidat $x$ est meilleur qu'un candidat $y$ en montrant comment ses points forts compensent ses points faibles via des modèles d'optimisation (MIP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a1d06",
   "metadata": {},
   "source": [
    "## 2. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adadbf4",
   "metadata": {},
   "source": [
    "Dans cette section, nous définissons les poids des matières et les notes des candidats de référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee2af27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matieres = [\"Anatomie\", \"Biologie\", \"Chirurgie\", \"Diagnostic\", \"Epidemiologie\", \"Forensic Pathology\", \"Génétique\"]\n",
    "poids = [8, 7, 7, 6, 6, 5, 6]\n",
    "\n",
    "# Notes des candidats \n",
    "notes_x = [85, 81, 71, 69, 75, 81, 88] # Xavier\n",
    "notes_y = [81, 81, 75, 63, 67, 88, 95] # Yvonne\n",
    "notes_z = [74, 89, 74, 81, 68, 84, 79]\n",
    "notes_t = [74, 71, 84, 91, 77, 76, 73]\n",
    "notes_w = [79, 69, 78, 76, 67, 84, 79]\n",
    "notes_w_prime = [57, 76, 81, 76, 82, 86, 77]\n",
    "notes_u = [72, 66, 75, 85, 88, 66, 93]\n",
    "notes_v = [71, 73, 63, 92, 76, 79, 93]\n",
    "\n",
    "# Autres candidats\n",
    "notes_a1 = [89, 74, 81, 68, 84, 79, 77]\n",
    "notes_a2 = [71, 84, 91, 79, 78, 73.5, 77] # 73.5 pour Forensic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5550a96",
   "metadata": {},
   "source": [
    "Fonctions utilitaires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade6cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparer_donnees(notes_a, notes_b, poids):\n",
    "    \"\"\"Calcule les contributions et sépare les Pros et les Cons.\"\"\"\n",
    "    contribs = [poids[i] * (notes_a[i] - notes_b[i]) for i in range(len(poids))]\n",
    "    P = [i for i, c in enumerate(contribs) if c > 0]\n",
    "    C = [i for i, c in enumerate(contribs) if c < 0]\n",
    "    return contribs, P, C\n",
    "\n",
    "def afficher_resultats(titre, status, explication):\n",
    "    \"\"\"Affiche proprement le résultat d'un modèle d'optimisation.\"\"\"\n",
    "    print(f\"\\n=== {titre} ===\")\n",
    "    if status == \"OPTIMAL\" and explication:\n",
    "        print(\"SUCCÈS : Une explication a été trouvée :\")\n",
    "        for groupe in explication:\n",
    "            print(f\"  • {groupe}\")\n",
    "    else:\n",
    "        print(\"ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e912180",
   "metadata": {},
   "source": [
    "## 3. Question 1 : Explication de type (1-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63351696",
   "metadata": {},
   "source": [
    "**Démarche** : Nous cherchons à coupler chaque critère défavorable à un unique critère favorable qui le compense individuellement.\n",
    "\n",
    "**Contrainte** : Chaque \"Pro\" est utilisé au plus une fois, chaque \"Con\" est couvert une fois.\n",
    "\n",
    "**Condition** : $c_{pro} + c_{con} > 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879e0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explication_1_1(notes_a, notes_b, poids, features):\n",
    "    \"\"\"\n",
    "    Calcule une explication de type (1-1) où chaque point fort compense un unique point faible.\n",
    "    \n",
    "    Args:\n",
    "        notes_a (list): Notes du candidat supérieur.\n",
    "        notes_b (list): Notes du candidat inférieur.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (status, explication) où status est \"OPTIMAL\" ou \"INFEASIBLE\" \n",
    "               et explication est une liste de chaînes décrivant les binômes.\n",
    "    \"\"\"\n",
    "    contribs, P, C = preparer_donnees(notes_a, notes_b, poids)\n",
    "    \n",
    "    m = gp.Model(\"Q1_1_1\")\n",
    "    m.Params.OutputFlag = 0\n",
    "    \n",
    "    # x[i,j] = 1 si le pro i compense le con j\n",
    "    x = m.addVars(P, C, vtype=GRB.BINARY, name=\"x\")\n",
    "    \n",
    "    # Contraintes : Couplage parfait\n",
    "    for j in C:\n",
    "        m.addConstr(gp.quicksum(x[i,j] for i in P) == 1)\n",
    "    for i in P:\n",
    "        m.addConstr(gp.quicksum(x[i,j] for j in C) <= 1)\n",
    "        \n",
    "    # Validité : pro + con > 0\n",
    "    for i in P:\n",
    "        for j in C:\n",
    "            if contribs[i] + contribs[j] <= 0:\n",
    "                m.addConstr(x[i,j] == 0)\n",
    "\n",
    "    m.optimize()\n",
    "    \n",
    "    if m.Status == GRB.OPTIMAL:\n",
    "        res = [f\"{features[i]} (+{contribs[i]}) compense {features[j]} ({contribs[j]})\" \n",
    "                       for i in P for j in C if x[i,j].X > 0.5]\n",
    "        return \"OPTIMAL\", res\n",
    "    return \"INFEASIBLE\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92749bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2027-11-29\n",
      "\n",
      "=== QUESTION 1 (1-1) : Xavier vs Yvonne ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Anatomie (+32) compense Chirurgie (-28)\n",
      "  • Diagnostic (+36) compense Forensic Pathology (-35)\n",
      "  • Epidemiologie (+48) compense Génétique (-42)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "status, explication = explication_1_1(notes_x, notes_y, poids, matieres)\n",
    "afficher_resultats(\"QUESTION 1 (1-1) : Xavier vs Yvonne\", status, explication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa81471",
   "metadata": {},
   "source": [
    "## 4. Question 2: Explication (1-m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7283dcfc",
   "metadata": {},
   "source": [
    "**Démarche** : Nous généralisons le modèle.\n",
    "\n",
    "**Type (1-m)** : Un avantage puissant peut compenser plusieurs faiblesses. C'est utile quand un candidat excelle dans une matière à gros coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a38012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explication_1_m(notes_a, notes_b, poids, features, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Calcule une explication de type (1-m) où un point fort peut compenser plusieurs points faibles.\n",
    "    \n",
    "    Args:\n",
    "        notes_a (list): Notes du candidat supérieur.\n",
    "        notes_b (list): Notes du candidat inférieur.\n",
    "        poids (list): Coefficients des matières.\n",
    "        features (list): Noms des matières.\n",
    "        epsilon (float): Seuil de supériorité pour le trade-off.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (status, explication) où explication est une liste de chaînes.\n",
    "    \"\"\"\n",
    "    # Calcul des contributions\n",
    "    contribs, P, C = preparer_donnees(notes_a, notes_b, poids)\n",
    "    \n",
    "    # Modèle Gurobi\n",
    "    m = gp.Model(\"Explication_1_m\")\n",
    "    m.setParam('OutputFlag', 0) # Mode silencieux\n",
    "\n",
    "    # Variables\n",
    "    # x[i,j] = 1 si Pro i couvre Con j\n",
    "    x = {}\n",
    "    for i in P:\n",
    "        for j in C:\n",
    "            x[i, j] = m.addVar(vtype=GRB.BINARY, name=f\"link_{i}_{j}\")\n",
    "    \n",
    "    # y[i] = 1 si Pro i est utilisé\n",
    "    y = {}\n",
    "    for i in P:\n",
    "        y[i] = m.addVar(vtype=GRB.BINARY, name=f\"use_{i}\")\n",
    "\n",
    "    # Contrainte C1: Chaque Con doit être couvert exactement une fois\n",
    "    for j in C:\n",
    "        m.addConstr(gp.quicksum(x[i, j] for i in P) == 1, name=f\"cover_{j}\")\n",
    "\n",
    "    # Contrainte C2: Lien x_ij <= y_i\n",
    "    for i in P:\n",
    "        for j in C:\n",
    "            m.addConstr(x[i, j] <= y[i], name=f\"link_logic_{i}_{j}\")\n",
    "\n",
    "    # Contrainte C3: Somme pondérée positive pour chaque groupe (1-m)\n",
    "    # delta_i * y_i + sum(contribs_j * x_ij) >= epsilon * y_i\n",
    "    for i in P:\n",
    "        sum_cons = gp.quicksum(contribs[j] * x[i, j] for j in C)\n",
    "        m.addConstr(contribs[i] * y[i] + sum_cons >= epsilon * y[i], name=f\"validity_{i}\")\n",
    "\n",
    "    # Résolution\n",
    "    m.optimize()\n",
    "\n",
    "    # Analyse\n",
    "    if m.Status == GRB.OPTIMAL:\n",
    "        res = []\n",
    "        for i in P:\n",
    "            if y[i].X > 0.5:\n",
    "                cons = [features[j] for j in C if x[i, j].X > 0.5]\n",
    "                res.append(f\"{features[i]} compense le groupe {cons}\")\n",
    "        return \"OPTIMAL\", res\n",
    "    elif m.Status == GRB.INFEASIBLE:\n",
    "        return \"INFEASIBLE\", None\n",
    "    else:\n",
    "        return f\"Status {m.Status}\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa72382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUESTION 2 (1-m) : w vs w' ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Anatomie compense le groupe ['Biologie', 'Chirurgie', 'Epidemiologie', 'Forensic Pathology']\n",
      "  • Génétique compense le groupe []\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "status, result = explication_1_m(notes_w, notes_w_prime, poids, matieres)\n",
    "afficher_resultats(\"QUESTION 2 (1-m) : w vs w'\", status, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4eafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUESTION 2 (1-m) : u vs v ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "status, result = explication_1_m(notes_u, notes_v, poids, matieres)\n",
    "afficher_resultats(\"QUESTION 2 (1-m) : u vs v\", status, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97a238",
   "metadata": {},
   "source": [
    "## 5. Question 3: Explication (m-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e4433",
   "metadata": {},
   "source": [
    "**Démarche** : Nous généralisons le modèle.\n",
    "\n",
    "**Type (m-1)** : Plusieurs petits avantages s'unissent pour compenser une faiblesse majeure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be984b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explication_m_1(candidate_sup, candidate_inf, notes_a, notes_b, poids, features):\n",
    "    \"\"\"\n",
    "    Calcule une explication de type (m-1) où plusieurs points forts s'unissent \n",
    "    pour compenser un seul point faible.\n",
    "    \n",
    "    Args:\n",
    "        notes_a (list): Notes du candidat supérieur.\n",
    "        notes_b (list): Notes du candidat inférieur.\n",
    "        poids (list): Coefficients des matières.\n",
    "        features (list): Noms des matières.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (status, explication) où explication est une liste de chaînes.\n",
    "    \"\"\"\n",
    "    # Calcul des contributions\n",
    "    contribs, P, C = preparer_donnees(notes_a, notes_b, poids)\n",
    "\n",
    "    # Modèle Gurobi\n",
    "    m = gp.Model(f\"Explication_m_1_{candidate_sup}_{candidate_inf}\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    # Variables x[i, j] : Pro i aide à couvrir Con j\n",
    "    x = {}\n",
    "    for i in P:\n",
    "        for j in C:\n",
    "            x[i, j] = m.addVar(vtype=GRB.BINARY, name=f\"x_{features[i]}_{features[j]}\")\n",
    "\n",
    "    # Contrainte C1: Chaque Pro utilisé au max 1 fois\n",
    "    for i in P:\n",
    "        m.addConstr(gp.quicksum(x[i, j] for j in C) <= 1, name=f\"disjoint_{features[i]}\")\n",
    "\n",
    "    # Contrainte C2: Chaque Con doit être compensé (Somme Pros + Con >= 0)\n",
    "    for j in C:\n",
    "        m.addConstr(gp.quicksum(contribs[i] * x[i, j] for i in P) + contribs[j] >= 0, \n",
    "                    name=f\"cover_{features[j]}\")\n",
    "\n",
    "    # Résolution\n",
    "    m.optimize()\n",
    "\n",
    "    # Analyse\n",
    "    if m.Status == GRB.OPTIMAL:\n",
    "        res = []\n",
    "        for j in C:\n",
    "            avantages = [features[i] for i in P if x[i,j].X > 0.5]\n",
    "            res.append(f\"L'union de {avantages} compense {features[j]} ({contribs[j]})\")\n",
    "        return \"OPTIMAL\", res\n",
    "    return \"INFEASIBLE\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efe90b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUESTION 3 (m-1) : Candidat y vs z ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • L'union de ['Anatomie'] compense Biologie (-56)\n",
      "  • L'union de ['Forensic Pathology', 'Génétique'] compense Diagnostic (-108)\n",
      "  • L'union de ['Chirurgie'] compense Epidemiologie (-6)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "status, result = explication_m_1(\"y\", \"z\", notes_y, notes_z, poids, matieres)\n",
    "afficher_resultats(\"QUESTION 3 (m-1) : Candidat y vs z\", status, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a9e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUESTION 3 (m-1) : Candidat z vs t ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "status, result = explication_m_1(\"z\", \"t\", notes_z, notes_t, poids, matieres)\n",
    "afficher_resultats(\"QUESTION 3 (m-1) : Candidat z vs t\", status, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcda3a6",
   "metadata": {},
   "source": [
    "## 6. Question 4: Modèle Hybride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03a8ef",
   "metadata": {},
   "source": [
    "**Démarche** : Certains cas, comme $u > v$, ne possèdent pas d'explication simple. Nous implémentons un modèle hybride qui autorise une partition arbitraire des critères en groupes (1-m) ou (m-1). Nous utilisons une formulation avec des variables binaires et des contraintes de type \"Big-M\" pour activer les trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9a4399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explication_hybride(notes_a, notes_b, poids, features):\n",
    "    \"\"\"\n",
    "    Résout le problème d'explication mixte (Question 4).\n",
    "    Autorise la création d'une partition flexible combinant des structures (1-m) et (m-1).\n",
    "    \n",
    "    Args:\n",
    "        notes_a (list): Notes du candidat supérieur.\n",
    "        notes_b (list): Notes du candidat inférieur.\n",
    "        epsilon (float): Seuil de supériorité pour valider un groupe.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (status, explication) où explication est une liste de chaînes de caractères.\n",
    "    \"\"\"\n",
    "    # Calcul des contributions\n",
    "    contribs, P, C = preparer_donnees(notes_a, notes_b, poids)\n",
    "\n",
    "    # Modèle\n",
    "    m = gp.Model(\"Mixed_Explanation\")\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    \n",
    "    # Variables de liaison pour les deux types de structures\n",
    "    x_1m = {} # x_1m[i,j] = 1 si le Pro i (Hub) couvre le Con j\n",
    "    x_m1 = {} # x_m1[i,j] = 1 si le Con j (Hub) est couvert par le Pro i\n",
    "\n",
    "    for i in P:\n",
    "        for j in C:\n",
    "            x_1m[i, j] = m.addVar(vtype=GRB.BINARY, name=f\"1m_{features[i]}_{features[j]}\")\n",
    "            x_m1[i, j] = m.addVar(vtype=GRB.BINARY, name=f\"m1_{features[i]}_{features[j]}\")\n",
    "\n",
    "    # Indicateurs de rôle \"Hub\"\n",
    "    # h_P[i] = 1 si le Pro i est utilisé comme centre d'un (1-m)\n",
    "    h_P = {i: m.addVar(vtype=GRB.BINARY) for i in P}\n",
    "    \n",
    "    # h_C[j] = 1 si le Con j est utilisé comme centre d'un (m-1)\n",
    "    h_C = {j: m.addVar(vtype=GRB.BINARY) for j in C}\n",
    "\n",
    "    # Contraintes\n",
    "    # Contrainte C1: Tout Con doit être couvert exactement une fois\n",
    "    for j in C:\n",
    "        m.addConstr(gp.quicksum(x_1m[i, j] for i in P) + h_C[j] == 1, name=f\"Cover_{j}\")\n",
    "\n",
    "    # Contrainte C2: Tout Pro utilisé au max une fois\n",
    "    for i in P:\n",
    "        m.addConstr(h_P[i] + gp.quicksum(x_m1[i, j] for j in C) <= 1, name=f\"Use_{i}\")\n",
    "\n",
    "    # Contrainte C3: Cohérence logique des liens\n",
    "    for i in P:\n",
    "        for j in C:\n",
    "            m.addConstr(x_1m[i, j] <= h_P[i], name=f\"Logic_1m_{i}_{j}\")\n",
    "            m.addConstr(x_m1[i, j] <= h_C[j], name=f\"Logic_m1_{i}_{j}\")\n",
    "\n",
    "    # Contrainte C4: Validité des Trade-offs (Somme pondérée > 0)\n",
    "    \n",
    "    for i in P: # Pour chaque Pro Hub (Structure 1-m): delta_i + sum(delta_j * x_1m_ij) >= 0\n",
    "        contrib_cons = gp.quicksum(contribs[j] * x_1m[i, j] for j in C)\n",
    "        m.addConstr(contribs[i] * h_P[i] + contrib_cons >= 0, name=f\"Valid_1m_{i}\")\n",
    "    \n",
    "    for j in C: # Pour chaque Con Hub (Structure m-1): sum(delta_i * x_m1_ij) + delta_j >= 0\n",
    "        contrib_pros = gp.quicksum(contribs[i] * x_m1[i, j] for i in P)\n",
    "        m.addConstr(contrib_pros + contribs[j] * h_C[j] >= 0, name=f\"Valid_m1_{j}\")\n",
    "\n",
    "    # Résolution\n",
    "    m.optimize()\n",
    "\n",
    "    # Analyse\n",
    "    if m.Status == GRB.OPTIMAL:\n",
    "        res = []\n",
    "        # Structures (1-m)\n",
    "        for i in P:\n",
    "            if h_P[i].X > 0.5:\n",
    "                cons_covered = [features[j] for j in C if x_1m[i, j].X > 0.5]\n",
    "                if cons_covered:\n",
    "                    res.append(f\"Groupe (1-m) : L'avantage {features[i]} (+{contribs[i]}) compense {cons_covered}\")\n",
    "        \n",
    "        # Structures (m-1)\n",
    "        for j in C:\n",
    "            if h_C[j].X > 0.5:\n",
    "                pros_used = [features[i] for i in P if x_m1[i, j].X > 0.5]\n",
    "                val_pros = sum(contribs[i] for i in P if x_m1[i, j].X > 0.5)\n",
    "                res.append(f\"Groupe (m-1) : Les avantages {pros_used} (+{val_pros}) compensent {features[j]} ({contribs[j]})\")\n",
    "        \n",
    "        return \"OPTIMAL\", res\n",
    "    \n",
    "    return \"INFEASIBLE\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc1213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUESTION 4 (hybride) : Candidat z vs t ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage Biologie (+126) compense ['Diagnostic', 'Epidemiologie']\n",
      "  • Groupe (m-1) : Les avantages ['Forensic Pathology', 'Génétique'] (+76) compensent Chirurgie (-70)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "status, result = explication_hybride(notes_z, notes_t, poids, matieres)\n",
    "afficher_resultats(\"QUESTION 4 (hybride) : Candidat z vs t\", status, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87ff99f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUESTION 4 (hybride) : Candidat a1 vs a2 ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "status, result = explication_hybride(notes_a1, notes_a2, poids, matieres)\n",
    "afficher_resultats(\"QUESTION 4 (hybride) : Candidat a1 vs a2\", status, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc7814",
   "metadata": {},
   "source": [
    "## 7. Application aux données réelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf5ae2",
   "metadata": {},
   "source": [
    "### 1. Dataset Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e69da775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3047e3e",
   "metadata": {},
   "source": [
    "L'idée est de passer d'une approche boîte noire (la Régression Logistique qui prédit un diagnostic) à une approche explicable (justifier pourquoi le patient A est considéré comme plus sain que le patient B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8db02b",
   "metadata": {},
   "source": [
    "Le modèle de décision ici n'est pas donné a priori. On commence donc par entraîner une Régression Logistique sur le dataset. Afin d'en extraire les coefficients ($w$). \n",
    "\n",
    "Ce sont ces poids qui représentent l'importance accordée par l'IA à chaque critère (taille de la cellule, épaisseur, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13149f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "breastcancer_data = pd.read_csv(\"data/breastcancer_processed.csv\")\n",
    "breastcancer_data.head()\n",
    "breastcancer_X, breastcancer_y = breastcancer_data.drop(columns=\"Benign\"), breastcancer_data[\"Benign\"]\n",
    "breastcancer_feature_names = breastcancer_X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb70c8",
   "metadata": {},
   "source": [
    "Il faut ensuite standardiser les données (on va utiliser StandardScaler), pour éviter qu'un critère avec de grandes valeurs numériques écrase les autres, et ce qui ferait que les explications de trade-off ne voudront rien dire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "642303d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "breastcancer_X_scaled = scaler.fit_transform(breastcancer_X)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(breastcancer_X_scaled, breastcancer_y)\n",
    "\n",
    "breastcancer_weights = model.coef_[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70580d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse de 100 paires aléatoires...\n",
      "\n",
      "=== BILAN EXPLICABILITÉ BREAST CANCER ===\n",
      "Nombre de paires testées : 100\n",
      "Nombre de paires sans explication : 2\n",
      "Proportion de paires non-explicables : 2.00%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluer_explicabilite_dataset(X, poids, names, n_paires=100):\n",
    "    \"\"\"\n",
    "    Echantillonne des paires (x, y) et calcule la proportion d'échecs d'explication.\n",
    "    \"\"\"\n",
    "    scores = X @ poids\n",
    "    indices = list(range(len(X)))\n",
    "    paires_testees = 0\n",
    "    echecs = 0\n",
    "\n",
    "    print(f\"Analyse de {n_paires} paires aléatoires...\")\n",
    "    \n",
    "    while paires_testees < n_paires:\n",
    "        # On tire deux patients au hasard\n",
    "        idx_a, idx_b = random.sample(indices, 2)\n",
    "        \n",
    "        # On s'assure de comparer le meilleur au moins bon\n",
    "        if scores[idx_a] >= scores[idx_b]:\n",
    "            patient_sup, patient_inf = X[idx_a], X[idx_b]\n",
    "        else:\n",
    "            patient_sup, patient_inf = X[idx_b], X[idx_a]\n",
    "            \n",
    "        # Tentative d'explication avec la fonction hybride\n",
    "        status, _ = explication_hybride(patient_sup, patient_inf, poids, names)\n",
    "        \n",
    "        if status != \"OPTIMAL\":\n",
    "            echecs += 1\n",
    "        \n",
    "        paires_testees += 1\n",
    "\n",
    "    taux_echec = (echecs / n_paires) * 100\n",
    "    return echecs, n_paires, taux_echec\n",
    "\n",
    "n_samples = 100\n",
    "nb_echecs, total, proportion = evaluer_explicabilite_dataset(breastcancer_X_scaled, breastcancer_weights, breastcancer_feature_names, n_samples)\n",
    "\n",
    "print(f\"\\n=== BILAN EXPLICABILITÉ BREAST CANCER ===\")\n",
    "print(f\"Nombre de paires testées : {total}\")\n",
    "print(f\"Nombre de paires sans explication : {nb_echecs}\")\n",
    "print(f\"Proportion de paires non-explicables : {proportion:.2f}%\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21735127",
   "metadata": {},
   "source": [
    "On observe une forte explicabilité: 98 % des décisions prises par l'IA sur le cancer du sein peuvent être justifiées par des compensations simples (un avantage qui compense plusieurs inconvénients, ou inversement). Cela montre que le diagnostic n'est pas une boîte noire complexe, mais une balance logique de symptômes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e956ce32",
   "metadata": {},
   "source": [
    "Les 2 paires inexplicables représentent des cas où la décision de la régression logistique est holistique. C'est-à-dire que le modèle a pris sa décision en additionnant une multitude de micro-facteurs qui, isolés, ne sont pas assez forts pour compenser un gros point négatif, mais qui, tous ensemble, font pencher la balance. \n",
    "\n",
    "Comme le modèle d'explication hybride force le regroupement autour d'un \"Hub\" (soit 1-m, soit m-1), il ne peut pas capturer ces cas de somme globale diffuse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831125cf",
   "metadata": {},
   "source": [
    "On teste avec un sampling plus élevé pour vérifier la robustesse de nos résultats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67669197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse de 500 paires aléatoires...\n",
      "\n",
      "=== BILAN EXPLICABILITÉ BREAST CANCER ===\n",
      "Nombre de paires testées : 500\n",
      "Nombre de paires sans explication : 1\n",
      "Proportion de paires non-explicables : 0.20%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_samples = 500\n",
    "nb_echecs, total, proportion = evaluer_explicabilite_dataset(breastcancer_X_scaled, breastcancer_weights, breastcancer_feature_names, n_samples)\n",
    "\n",
    "print(f\"\\n=== BILAN EXPLICABILITÉ BREAST CANCER ===\")\n",
    "print(f\"Nombre de paires testées : {total}\")\n",
    "print(f\"Nombre de paires sans explication : {nb_echecs}\")\n",
    "print(f\"Proportion de paires non-explicables : {proportion:.2f}%\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2a192",
   "metadata": {},
   "source": [
    "On cherche maintenant à identifier précisément pourquoi le modèle échoue sur ces paires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daa7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse de 500 paires...\n",
      "Nombre d'échecs trouvés : 4\n"
     ]
    }
   ],
   "source": [
    "def isoler_paires_echec(X, poids, names, n_paires=500):\n",
    "    \"\"\"\n",
    "    Échantillonne aléatoirement des paires de données et identifie celles pour lesquelles \n",
    "    le modèle d'explication hybride ne parvient pas à trouver de solution optimale.\n",
    "\n",
    "    Cette fonction permet de mesurer empiriquement la couverture du langage d'explication \n",
    "    (trade-offs 1-m et m-1) sur un dataset complexe comme celui du Breast Cancer.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray ou pd.DataFrame): Les features standardisées.\n",
    "        poids (list ou numpy.array): Les coefficients du modèle de régression logistique.\n",
    "        names (list): Liste des noms des features.\n",
    "        n_paires (int, optionnel): Nombre de paires à tester par échantillonnage aléatoire. \n",
    "                                   Par défaut 500.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Une liste de tuples (idx_superieur, idx_inferieur) contenant les \n",
    "                        indices des paires jugées inexplicables par le modèle hybride.\n",
    "    \"\"\"\n",
    "    scores = X @ poids\n",
    "    indices = list(range(len(X)))\n",
    "    paires_echec = []\n",
    "    \n",
    "    print(f\"Analyse de {n_paires} paires...\")\n",
    "    \n",
    "    found = 0\n",
    "    while found < n_paires:\n",
    "        idx_a, idx_b = random.sample(indices, 2)\n",
    "        if scores[idx_a] >= scores[idx_b]:\n",
    "            p_sup, p_inf = X[idx_a], X[idx_b]\n",
    "            indices_paire = (idx_a, idx_b)\n",
    "        else:\n",
    "            p_sup, p_inf = X[idx_b], X[idx_a]\n",
    "            indices_paire = (idx_b, idx_a)\n",
    "            \n",
    "        status, _ = explication_hybride(p_sup, p_inf, poids, names)\n",
    "        \n",
    "        if status != \"OPTIMAL\":\n",
    "            paires_echec.append(indices_paire)\n",
    "        \n",
    "        found += 1\n",
    "    \n",
    "    return paires_echec\n",
    "\n",
    "liste_echecs = isoler_paires_echec(breastcancer_X_scaled, breastcancer_weights, breastcancer_feature_names, 500)\n",
    "print(f\"Nombre d'échecs trouvés : {len(liste_echecs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c32e1807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Détail de l'échec (Patient 441 vs 252) ===\n",
      "Top Avantages (Pros) :\n",
      "                 Feature  Contribution\n",
      "          BlandChromatin      1.169578\n",
      "          NormalNucleoli      0.987644\n",
      "SingleEpithelialCellSize      0.224811\n",
      "    UniformityOfCellSize      0.077884\n",
      "          ClumpThickness      0.000000\n",
      "\n",
      "Pires Inconvénients (Cons) :\n",
      "              Feature  Contribution\n",
      "       ClumpThickness      0.000000\n",
      "           BareNuclei      0.000000\n",
      "     MarginalAdhesion     -0.560698\n",
      "UniformityOfCellShape     -0.807866\n",
      "              Mitoses     -0.835164\n",
      "\n",
      "Somme totale des avantages : 2.4599\n",
      "Pire inconvénient individuel : -0.8352\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Détail de l'échec (Patient 220 vs 120) ===\n",
      "Top Avantages (Pros) :\n",
      "         Feature  Contribution\n",
      "  NormalNucleoli      1.185173\n",
      "  BlandChromatin      1.169578\n",
      "MarginalAdhesion      0.560698\n",
      "  ClumpThickness      0.000000\n",
      "      BareNuclei      0.000000\n",
      "\n",
      "Pires Inconvénients (Cons) :\n",
      "                 Feature  Contribution\n",
      "              BareNuclei      0.000000\n",
      "    UniformityOfCellSize     -0.389421\n",
      "SingleEpithelialCellSize     -0.674433\n",
      "   UniformityOfCellShape     -0.807866\n",
      "                 Mitoses     -0.835164\n",
      "\n",
      "Somme totale des avantages : 2.9154\n",
      "Pire inconvénient individuel : -0.8352\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Détail de l'échec (Patient 110 vs 51) ===\n",
      "Top Avantages (Pros) :\n",
      "         Feature  Contribution\n",
      "  ClumpThickness      2.350709\n",
      "      BareNuclei      0.711109\n",
      "MarginalAdhesion      0.560698\n",
      "  BlandChromatin      0.000000\n",
      "  NormalNucleoli      0.000000\n",
      "\n",
      "Pires Inconvénients (Cons) :\n",
      "                 Feature  Contribution\n",
      "          NormalNucleoli      0.000000\n",
      "    UniformityOfCellSize     -0.155768\n",
      "   UniformityOfCellShape     -0.538577\n",
      "SingleEpithelialCellSize     -0.899243\n",
      "                 Mitoses     -1.670328\n",
      "\n",
      "Somme totale des avantages : 3.6225\n",
      "Pire inconvénient individuel : -1.6703\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Détail de l'échec (Patient 104 vs 642) ===\n",
      "Top Avantages (Pros) :\n",
      "              Feature  Contribution\n",
      "       ClumpThickness      1.410425\n",
      "UniformityOfCellShape      0.538577\n",
      "     MarginalAdhesion      0.280349\n",
      " UniformityOfCellSize      0.155768\n",
      "           BareNuclei      0.000000\n",
      "\n",
      "Pires Inconvénients (Cons) :\n",
      "                 Feature  Contribution\n",
      "              BareNuclei      0.000000\n",
      "SingleEpithelialCellSize     -0.112405\n",
      "          NormalNucleoli     -0.197529\n",
      "                 Mitoses     -0.835164\n",
      "          BlandChromatin     -1.169578\n",
      "\n",
      "Somme totale des avantages : 2.3851\n",
      "Pire inconvénient individuel : -1.1696\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyser_detail_echec(paire, X, poids, names):\n",
    "    \"\"\"\n",
    "    Réalise une analyse de l'échec de l'explication pour une paire donnée.\n",
    "    \n",
    "    Cette fonction décompose les contributions de chaque caractéristique médicale\n",
    "    pour identifier pourquoi les contraintes de partitionnement (1-m ou m-1) \n",
    "    n'ont pas pu être satisfaites par le solveur Gurobi, malgré un score global positif.\n",
    "\n",
    "    Args:\n",
    "        paire (tuple): Un tuple (idx_superieur, idx_inferieur) issu de isoler_paires_echec.\n",
    "        X (numpy.ndarray): Matrice des caractéristiques standardisées.\n",
    "        poids (list): Vecteur des coefficients du modèle de régression logistique.\n",
    "        names (list): Noms des variables médicales (sans la colonne cible).\n",
    "\n",
    "    Returns:\n",
    "        None: Affiche les tableaux de contributions et les statistiques de synthèse.\n",
    "    \"\"\"\n",
    "    idx_sup, idx_inf = paire\n",
    "    \n",
    "    notes_sup = X[idx_sup]\n",
    "    notes_inf = X[idx_inf]\n",
    "    contribs, P, C = preparer_donnees(notes_sup, notes_inf, poids)\n",
    "\n",
    "    df_contribs = pd.DataFrame({\n",
    "        'Feature': names,\n",
    "        'Contribution': contribs\n",
    "    }).sort_values(by='Contribution', ascending=False)\n",
    "\n",
    "    print(f\"\\n=== Détail de l'échec (Patient {idx_sup} vs {idx_inf}) ===\")\n",
    "    print(\"Top Avantages (Pros) :\")\n",
    "    print(df_contribs.head(5).to_string(index=False))\n",
    "    print(\"\\nPires Inconvénients (Cons) :\")\n",
    "    print(df_contribs.tail(5).to_string(index=False))\n",
    "    \n",
    "    pros_sum = sum(contribs[i] for i in P)\n",
    "    cons_min = min(contribs) if C else 0\n",
    "    \n",
    "    print(f\"\\nSomme totale des avantages : {pros_sum:.4f}\")\n",
    "    print(f\"Pire inconvénient individuel : {cons_min:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "if liste_echecs:\n",
    "    for i in range(len(liste_echecs)):\n",
    "        analyser_detail_echec(liste_echecs[i], breastcancer_X_scaled, breastcancer_weights, breastcancer_feature_names)\n",
    "else:\n",
    "    print(\"Aucun échec trouvé dans cet échantillon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7822a325",
   "metadata": {},
   "source": [
    "L'analyse des paires inexplicables révèle que l'échec ne provient pas d'une contradiction du modèle (la somme des contributions reste positive), mais d'une limite du langage d'explication.\n",
    "\n",
    "Le modèle hybride impose que chaque argument appartienne à une structure simple (soit un avantage pour plusieurs défauts, soit l'inverse). Dans les cas d'échec rencontrés, les faiblesses médicales du patient sont trop éparpillées: il y a plusieurs inconvénients de taille moyenne qui nécessiteraient une structure de type n-m (plusieurs avantages pour plusieurs inconvénients), ce que le modèle hybride interdit pour rester intelligible.\n",
    "\n",
    "Cela démontre qu'l existe une frange de diagnostics médicaux où la décision repose sur une interaction complexe et globale de tous les symptômes simultanément, rendant toute simplification par groupes de compensation incomplète."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d1641",
   "metadata": {},
   "source": [
    "### 2. Dataset RATP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7271470",
   "metadata": {},
   "source": [
    "L'idée est d'expliquer, en utilisant les algorithmes développés, quelles stations de métro est plus prioritaire pour être rénové. \n",
    "\n",
    "On commence par faire un scoring en prenant la somme pondérée des features des stations pour avoir une idée de leur classement en terme de priorité de rénovation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calculated Scores ---\n",
      "Key 'Odéon (Ligne 4)': 9484.28\n",
      "Key 'Place d'Italie (Lign 6)': 9457.61\n",
      "Key 'Jussieu (Ligne 7)': 9436.20\n",
      "Key 'Nation (Ligne 9)': 9389.68\n",
      "Key 'La Motte Picquet-Grenelle (Ligne 10)': 9349.76\n",
      "Key 'Porte d'Orléans (Ligne 4)': 9328.05\n",
      "Key 'Daumenil (Ligne 6)': 9144.58\n",
      "Key 'Vaugirard (Ligne 12)': 9107.66\n",
      "Key 'Oberkampf (Ligne 9)': 9229.01\n",
      "Key 'Reuilly-Diderot (Ligne 1)': 9240.69\n",
      "\n",
      "--- Final Sorted Data ---\n",
      "{'Odéon (Ligne 4)': [85000.0, 8100.0, 35500.0, 3450.0, 75.0, 16.2, 88.0], \"Place d'Italie (Lign 6)\": [81000.0, 8100.0, 37500.0, 3150.0, 67.0, 17.6, 95.0], 'Jussieu (Ligne 7)': [74000.0, 8900.0, 37000.0, 4050.0, 68.0, 16.8, 79.0], 'Nation (Ligne 9)': [74000.0, 7100.0, 42000.0, 4550.0, 77.0, 15.2, 73.0], 'La Motte Picquet-Grenelle (Ligne 10)': [72000.0, 7500.0, 33000.0, 4250.0, 88.0, 13.2, 93.0], \"Porte d'Orléans (Ligne 4)\": [71000.0, 7300.0, 31500.0, 4600.0, 76.0, 15.8, 93.0], 'Reuilly-Diderot (Ligne 1)': [72000.0, 8700.0, 36000.0, 4000.0, 66.0, 16.6, 78.0], 'Oberkampf (Ligne 9)': [84000.0, 7900.0, 34000.0, 3300.0, 74.0, 15.8, 85.0], 'Daumenil (Ligne 6)': [79000.0, 6900.0, 39000.0, 3800.0, 67.0, 16.8, 79.0], 'Vaugirard (Ligne 12)': [57000.0, 7600.0, 40500.0, 3800.0, 82.0, 17.2, 77.0]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ratp_data = pd.read_csv('data/ratp_cleaned_data.csv', index_col=0, sep=';')\n",
    "ratp_weights = [0.021, 0.188, 0.038, 0.322, 16.124, 67.183, 16.124]\n",
    "ratp_feature_cols = ratp_data.columns.tolist()\n",
    "\n",
    "stations_dict = {}\n",
    "\n",
    "for index, row in ratp_data.iterrows():\n",
    "    station_name = index\n",
    "    values = row[ratp_feature_cols].values.tolist()\n",
    "    stations_dict[station_name] = values\n",
    "\n",
    "\n",
    "# 1. Create a dictionary of just the scores\n",
    "scores = {\n",
    "    key: sum(val * w for val, w in zip(values, ratp_weights)) \n",
    "    for key, values in stations_dict.items()\n",
    "}\n",
    "\n",
    "print(\"--- Calculated Scores ---\")\n",
    "for key, score in scores.items():\n",
    "    print(f\"Key '{key}': {score:.2f}\")\n",
    "\n",
    "\n",
    "# 3. Sort the original data based on these scores\n",
    "# We look up the score in the 'scores' dict we just made\n",
    "sorted_data = dict(sorted(\n",
    "    stations_dict.items(), \n",
    "    key=lambda item: scores[item[0]], \n",
    "    reverse=True\n",
    "))\n",
    "\n",
    "print(\"\\n--- Final Sorted Data ---\")\n",
    "print(sorted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca29ba",
   "metadata": {},
   "source": [
    "On voit alors que c'est la station Odéon qui est la plus susceptible à avoir besoin de rénovation. On cacule 1 à 1, dans l'ordre de la liste, l'explication fournie par notre algorithme (1-m) et (m-1) mélangé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed273292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DONNÉES RATP : La station Odéon (Ligne 4) vs Place d'Italie (Lign 6) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage peak-entering-passengers/h (+84.0) compense ['off-peak-entering-passengers/h']\n",
      "  • Groupe (m-1) : Les avantages ['off-peak-passing-passengers/h'] (+96.60000000000001) compensent Station degradation level ([0,20]  scale) (-94.05620000000015)\n",
      "  • Groupe (m-1) : Les avantages ['strategic priority [0,10]'] (+128.992) compensent connectivity index [0,100] (-112.868)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Place d'Italie (Lign 6) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Jussieu (Ligne 7) vs Nation (Ligne 9) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage peak-passing-passengers/h (+338.4) compense ['off-peak-passing-passengers/h', 'strategic priority [0,10]']\n",
      "  • Groupe (m-1) : Les avantages ['Station degradation level ([0,20]  scale)', 'connectivity index [0,100]'] (+204.2368000000001) compensent off-peak-entering-passengers/h (-190.0)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Nation (Ligne 9) vs La Motte Picquet-Grenelle (Ligne 10) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station La Motte Picquet-Grenelle (Ligne 10) vs Porte d'Orléans (Ligne 4) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage strategic priority [0,10] (+193.488) compense ['Station degradation level ([0,20]  scale)']\n",
      "  • Groupe (m-1) : Les avantages ['peak-entering-passengers/h', 'peak-passing-passengers/h', 'off-peak-entering-passengers/h'] (+115.6) compensent off-peak-passing-passengers/h (-112.7)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Porte d'Orléans (Ligne 4) vs Daumenil (Ligne 6) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (m-1) : Les avantages ['off-peak-passing-passengers/h'] (+257.6) compensent peak-entering-passengers/h (-168.0)\n",
      "  • Groupe (m-1) : Les avantages ['peak-passing-passengers/h', 'connectivity index [0,100]'] (+300.936) compensent off-peak-entering-passengers/h (-285.0)\n",
      "  • Groupe (m-1) : Les avantages ['strategic priority [0,10]'] (+145.11599999999999) compensent Station degradation level ([0,20]  scale) (-67.183)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Daumenil (Ligne 6) vs Vaugirard (Ligne 12) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage peak-entering-passengers/h (+462.00000000000006) compense ['peak-passing-passengers/h', 'off-peak-entering-passengers/h', 'strategic priority [0,10]']\n",
      "  • Groupe (m-1) : Les avantages ['connectivity index [0,100]'] (+32.248) compensent Station degradation level ([0,20]  scale) (-26.87319999999991)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Vaugirard (Ligne 12) vs Oberkampf (Ligne 9) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Oberkampf (Ligne 9) vs Reuilly-Diderot (Ligne 1) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ratp_data)-1):\n",
    "    station_i = ratp_data.index[i]\n",
    "    station_i1 = ratp_data.index[i+1]\n",
    "    notes_i = stations_dict[station_i]\n",
    "    notes_j = stations_dict[station_i1]\n",
    "    status, result = explication_hybride(notes_i, notes_j, ratp_weights, ratp_feature_cols)\n",
    "    afficher_resultats(f\"DONNÉES RATP : La station {station_i} vs {station_i1}\", status, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c884a41",
   "metadata": {},
   "source": [
    "On obtient alors les explicaitons suivantes :\n",
    "- Odéon -> Place d'Italie \n",
    "- Jussieu -> Nation \n",
    "- La Motte Picquet-Grenelle -> Porte D'Orléans\n",
    "- Porte d'Orléans -> Daumesnil\n",
    "- Daumenil -> Vaugirard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48fd6f",
   "metadata": {},
   "source": [
    "On essaie donc de \"boucher les trous évidents\" si on en trouve. Par exemple, on essaie d'expliquer que Place D'Italie prime sur Nation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0633a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DONNÉES RATP : La station Place d'Italie (Lign 6) vs Nation (Ligne 9) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage connectivity index [0,100] (+354.72799999999995) compense ['off-peak-entering-passengers/h', 'strategic priority [0,10]']\n",
      "  • Groupe (m-1) : Les avantages ['peak-entering-passengers/h', 'peak-passing-passengers/h', 'Station degradation level ([0,20]  scale)'] (+496.23920000000015) compensent off-peak-passing-passengers/h (-450.8)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Nation (Ligne 9) vs Porte d'Orléans (Ligne 4) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage off-peak-entering-passengers/h (+399.0) compense ['Station degradation level ([0,20]  scale)', 'connectivity index [0,100]']\n",
      "  • Groupe (m-1) : Les avantages ['peak-entering-passengers/h'] (+63.00000000000001) compensent peak-passing-passengers/h (-37.6)\n",
      "  • Groupe (m-1) : Les avantages ['strategic priority [0,10]'] (+16.124) compensent off-peak-passing-passengers/h (-16.1)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Odéon (Ligne 4) vs La Motte Picquet-Grenelle (Ligne 10) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (m-1) : Les avantages ['peak-entering-passengers/h'] (+273.0) compensent off-peak-passing-passengers/h (-257.6)\n",
      "  • Groupe (m-1) : Les avantages ['off-peak-entering-passengers/h', 'Station degradation level ([0,20]  scale)'] (+296.54900000000004) compensent strategic priority [0,10] (-209.612)\n",
      "  • Groupe (m-1) : Les avantages ['peak-passing-passengers/h'] (+112.8) compensent connectivity index [0,100] (-80.61999999999999)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Place d'Italie vs Nation\n",
    "station_place_italie = ratp_data.index[1]\n",
    "notes_place_italie = stations_dict[station_place_italie]\n",
    "station_nation = ratp_data.index[3]\n",
    "notes_nation = stations_dict[station_nation]\n",
    "status, result = explication_hybride(notes_place_italie, notes_nation, ratp_weights, ratp_feature_cols)\n",
    "afficher_resultats(f\"DONNÉES RATP : La station {station_place_italie} vs {station_nation}\", status, result)\n",
    "\n",
    "\n",
    "# Nation vs Porte d'Orléans\n",
    "station_nation = ratp_data.index[3]\n",
    "notes_nation = stations_dict[station_nation]\n",
    "station_porte_orleans = ratp_data.index[5]\n",
    "notes_porte_orleans = stations_dict[station_porte_orleans]\n",
    "status, result = explication_hybride(notes_nation, notes_porte_orleans, ratp_weights, ratp_feature_cols)\n",
    "afficher_resultats(f\"DONNÉES RATP : La station {station_nation} vs {station_porte_orleans}\", status, result)\n",
    "\n",
    "# Odéon vs La motte Picquet\n",
    "station_odeon = ratp_data.index[0]\n",
    "notes_odeon = stations_dict[station_odeon]\n",
    "station_la_motte_picquet = ratp_data.index[4]\n",
    "notes_la_motte_picquet = stations_dict[station_la_motte_picquet]\n",
    "status, result = explication_hybride(notes_odeon, notes_la_motte_picquet, ratp_weights, ratp_feature_cols)\n",
    "afficher_resultats(f\"DONNÉES RATP : La station {station_odeon} vs {station_la_motte_picquet}\", status, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239bd9c0",
   "metadata": {},
   "source": [
    "On a alors :\n",
    "- Odéon prime sur Place d'Italie\n",
    "- Odéon ne prime pas sur Jussieu pour l'instant\n",
    "- Odéon prime sur Nation par transitivité car Place d'Italie prime sur Nation\n",
    "- Odéon prime sur La Motte Picquet\n",
    "- Odéon prime sur Porte d'Orléans par transitivié car Nation prime sur Porte d'Orléans\n",
    "- Odéon prime sur Daumesnil par transitivité car Porte d'Orléans prime sur Daumesnil\n",
    "- Odéon prime sur Vaugirard par transitivité car Daumesnil prime sur Vaugirard\n",
    "- Odéon ne prime pas sur Oberkampf pour l'instant\n",
    "- Odéon ne prime pas sur Reuilly Diderot pour l'instant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc1e49",
   "metadata": {},
   "source": [
    "Afin de procéder avec les trois stations restantes, on essaie de voir quelles stations priment sur eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c10c8f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DONNÉES RATP : La station Odéon (Ligne 4) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Place d'Italie (Lign 6) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Nation (Ligne 9) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station La Motte Picquet-Grenelle (Ligne 10) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Porte d'Orléans (Ligne 4) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Daumenil (Ligne 6) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Vaugirard (Ligne 12) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Oberkampf (Ligne 9) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Reuilly-Diderot (Ligne 1) vs Jussieu (Ligne 7) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Odéon (Ligne 4) vs Oberkampf (Ligne 9) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Place d'Italie (Lign 6) vs Oberkampf (Ligne 9) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (m-1) : Les avantages ['connectivity index [0,100]'] (+161.23999999999998) compensent peak-entering-passengers/h (-63.00000000000001)\n",
      "  • Groupe (m-1) : Les avantages ['Station degradation level ([0,20]  scale)'] (+120.92940000000006) compensent off-peak-passing-passengers/h (-48.300000000000004)\n",
      "  • Groupe (m-1) : Les avantages ['off-peak-entering-passengers/h'] (+133.0) compensent strategic priority [0,10] (-112.868)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Jussieu (Ligne 7) vs Oberkampf (Ligne 9) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (m-1) : Les avantages ['off-peak-passing-passengers/h', 'Station degradation level ([0,20]  scale)'] (+308.683) compensent peak-entering-passengers/h (-210.0)\n",
      "  • Groupe (m-1) : Les avantages ['peak-passing-passengers/h'] (+188.0) compensent strategic priority [0,10] (-96.744)\n",
      "  • Groupe (m-1) : Les avantages ['off-peak-entering-passengers/h'] (+114.0) compensent connectivity index [0,100] (-96.744)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Nation (Ligne 9) vs Oberkampf (Ligne 9) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage off-peak-passing-passengers/h (+402.5) compense ['peak-passing-passengers/h', 'connectivity index [0,100]']\n",
      "  • Groupe (m-1) : Les avantages ['off-peak-entering-passengers/h'] (+304.0) compensent peak-entering-passengers/h (-210.0)\n",
      "  • Groupe (m-1) : Les avantages ['strategic priority [0,10]'] (+48.372) compensent Station degradation level ([0,20]  scale) (-40.3098000000001)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station La Motte Picquet-Grenelle (Ligne 10) vs Oberkampf (Ligne 9) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage off-peak-passing-passengers/h (+305.90000000000003) compense ['peak-entering-passengers/h', 'off-peak-entering-passengers/h']\n",
      "  • Groupe (1-m) : L'avantage strategic priority [0,10] (+225.736) compense ['Station degradation level ([0,20]  scale)']\n",
      "  • Groupe (1-m) : L'avantage connectivity index [0,100] (+128.992) compense ['peak-passing-passengers/h']\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Porte d'Orléans (Ligne 4) vs Oberkampf (Ligne 9) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage off-peak-passing-passengers/h (+418.6) compense ['peak-entering-passengers/h', 'off-peak-entering-passengers/h']\n",
      "  • Groupe (m-1) : Les avantages ['connectivity index [0,100]'] (+128.992) compensent peak-passing-passengers/h (-112.8)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Daumenil (Ligne 6) vs Oberkampf (Ligne 9) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Vaugirard (Ligne 12) vs Oberkampf (Ligne 9) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Reuilly-Diderot (Ligne 1) vs Oberkampf (Ligne 9) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Odéon (Ligne 4) vs Reuilly-Diderot (Ligne 1) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage peak-entering-passengers/h (+273.0) compense ['peak-passing-passengers/h', 'off-peak-entering-passengers/h', 'Station degradation level ([0,20]  scale)']\n",
      "  • Groupe (m-1) : Les avantages ['strategic priority [0,10]', 'connectivity index [0,100]'] (+306.356) compensent off-peak-passing-passengers/h (-177.1)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Place d'Italie (Lign 6) vs Reuilly-Diderot (Ligne 1) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (m-1) : Les avantages ['peak-entering-passengers/h'] (+189.0) compensent peak-passing-passengers/h (-112.8)\n",
      "  • Groupe (m-1) : Les avantages ['off-peak-entering-passengers/h', 'Station degradation level ([0,20]  scale)', 'connectivity index [0,100]'] (+398.291) compensent off-peak-passing-passengers/h (-273.7)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Jussieu (Ligne 7) vs Reuilly-Diderot (Ligne 1) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Nation (Ligne 9) vs Reuilly-Diderot (Ligne 1) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage strategic priority [0,10] (+177.36399999999998) compense ['Station degradation level ([0,20]  scale)', 'connectivity index [0,100]']\n",
      "  • Groupe (m-1) : Les avantages ['peak-entering-passengers/h', 'off-peak-entering-passengers/h', 'off-peak-passing-passengers/h'] (+447.1) compensent peak-passing-passengers/h (-300.8)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station La Motte Picquet-Grenelle (Ligne 10) vs Reuilly-Diderot (Ligne 1) ===\n",
      "SUCCÈS : Une explication a été trouvée :\n",
      "  • Groupe (1-m) : L'avantage strategic priority [0,10] (+354.72799999999995) compense ['peak-passing-passengers/h', 'off-peak-entering-passengers/h']\n",
      "  • Groupe (m-1) : Les avantages ['connectivity index [0,100]'] (+241.85999999999999) compensent Station degradation level ([0,20]  scale) (-228.42220000000017)\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Porte d'Orléans (Ligne 4) vs Reuilly-Diderot (Ligne 1) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Daumenil (Ligne 6) vs Reuilly-Diderot (Ligne 1) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Vaugirard (Ligne 12) vs Reuilly-Diderot (Ligne 1) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Oberkampf (Ligne 9) vs Reuilly-Diderot (Ligne 1) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Jussieu\n",
    "station_jussieu = ratp_data.index[2]\n",
    "notes_jussieu = stations_dict[station_jussieu]\n",
    "\n",
    "for i in range(len(ratp_data)):\n",
    "    if i == 2:\n",
    "        continue\n",
    "    station_i = ratp_data.index[i]\n",
    "    notes_i = stations_dict[station_i]\n",
    "    status, result = explication_hybride(notes_i, notes_jussieu, ratp_weights, ratp_feature_cols)\n",
    "    afficher_resultats(f\"DONNÉES RATP : La station {station_i} vs {station_jussieu}\", status, result)\n",
    "\n",
    "\n",
    "# Oberkampf\n",
    "station_oberkampf = ratp_data.index[8]\n",
    "notes_oberkampf = stations_dict[station_oberkampf]\n",
    "\n",
    "for i in range(len(ratp_data)):\n",
    "    if i == 8:\n",
    "        continue\n",
    "    station_i = ratp_data.index[i]\n",
    "    notes_i = stations_dict[station_i]\n",
    "    status, result = explication_hybride(notes_i, notes_oberkampf, ratp_weights, ratp_feature_cols)\n",
    "    afficher_resultats(f\"DONNÉES RATP : La station {station_i} vs {station_oberkampf}\", status, result)\n",
    "\n",
    "\n",
    "# Reuilly Diderot\n",
    "station_reuilly_diderot = ratp_data.index[9]\n",
    "notes_reuilly_diderot = stations_dict[station_reuilly_diderot]\n",
    "\n",
    "for i in range(len(ratp_data)):\n",
    "    if i == 9:\n",
    "        continue\n",
    "    station_i = ratp_data.index[i]\n",
    "    notes_i = stations_dict[station_i]\n",
    "    status, result = explication_hybride(notes_i, notes_reuilly_diderot, ratp_weights, ratp_feature_cols)\n",
    "    afficher_resultats(f\"DONNÉES RATP : La station {station_i} vs {station_reuilly_diderot}\", status, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a824035",
   "metadata": {},
   "source": [
    "On trouve alors les observations suivantes.\n",
    "- Odéon prime sur Oberkampf par transitivité car Place d'Italie prime sur Oberlampf.\n",
    "- Odéon prime sur Reuilly Diderot.\n",
    "\n",
    "Il n'y a aucune station qui prime sur Jussieu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f86ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DONNÉES RATP : La station Place d'Italie (Lign 6) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Jussieu (Ligne 7) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Nation (Ligne 9) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station La Motte Picquet-Grenelle (Ligne 10) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Porte d'Orléans (Ligne 4) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Daumenil (Ligne 6) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Vaugirard (Ligne 12) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Oberkampf (Ligne 9) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== DONNÉES RATP : La station Reuilly-Diderot (Ligne 1) vs Odéon (Ligne 4) ===\n",
      "ÉCHEC : Aucune explication de ce type n'est possible pour ces candidats.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Odéon\n",
    "station_odeon = ratp_data.index[0]\n",
    "notes_odeon = stations_dict[station_odeon]\n",
    "\n",
    "for i in range(len(ratp_data)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    station_i = ratp_data.index[i]\n",
    "    notes_i = stations_dict[station_i]\n",
    "    status, result = explication_hybride(notes_i, notes_odeon, ratp_weights, ratp_feature_cols)\n",
    "    afficher_resultats(f\"DONNÉES RATP : La station {station_i} vs {station_odeon}\", status, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce702b4a",
   "metadata": {},
   "source": [
    "Il n'y a aucune station qui prime sur Odéon non plus. On en déduit que, bien que Odéon prime sur toutes les autres station, et prime sur Jussieu en terme de somme pondérée des features, on ne peut pas l'expliquer avec nos algorithmes présent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb6452c",
   "metadata": {},
   "source": [
    "### 3. Données avec 27 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372ceaf6",
   "metadata": {},
   "source": [
    "\n",
    "L’objectif est d’analyser des comparaisons locales entre solutions à l’aide d’un langage d’explication fondé sur des trade-offs, **sans recourir à un classement global par score**.\n",
    "\n",
    "Chaque solution est décrite par 27 critères pondérés. Pour une comparaison donnée $x \\succ y$, on calcule pour chaque critère $k$ la contribution :\n",
    "\n",
    "$$\n",
    "c_k = w_k(x_k - y_k)\n",
    "$$\n",
    "\n",
    "Ces contributions permettent de distinguer :\n",
    "- les arguments favorables : $c_k > 0$,\n",
    "- les arguments défavorables : $c_k < 0$,\n",
    "- les arguments neutres : $c_k = 0$.\n",
    "\n",
    "Les ensembles ainsi obtenus constituent l’entrée du modèle d’explication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0cc1f",
   "metadata": {},
   "source": [
    "1. Chargement des données (poids + deux premières solutions pour démarrer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffb6c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_first_two_solutions_27crit(path: str):\n",
    "    raw = pd.read_excel(path, header=None)\n",
    "\n",
    "    col0 = raw[0].astype(str).str.strip().str.lower()\n",
    "    wrow_idx = raw.index[col0 == \"weight\"][0]\n",
    "\n",
    "    crit_row_idx = wrow_idx - 1\n",
    "    criteria = raw.loc[crit_row_idx, 1:].tolist()\n",
    "    criteria = [str(c).strip() for c in criteria]\n",
    "    criteria = [c for c in criteria if c and c.lower() != \"nan\"]\n",
    "\n",
    "    wvals = raw.loc[wrow_idx, 1: 1 + len(criteria)].tolist()\n",
    "    weights = [float(w) for w in wvals]\n",
    "\n",
    "    data = raw.loc[wrow_idx + 1:, :].copy()\n",
    "    data = data.dropna(how=\"all\")\n",
    "    data = data.rename(columns={0: \"solution\"})\n",
    "    data[\"solution\"] = data[\"solution\"].astype(str).str.strip()\n",
    "\n",
    "    s1 = data[data[\"solution\"].str.lower() == \"solution 1\"].iloc[0]\n",
    "    s2 = data[data[\"solution\"].str.lower() == \"solution 2\"].iloc[0]\n",
    "\n",
    "    notes_s1 = [float(s1[i]) for i in range(1, 1 + len(criteria))]\n",
    "    notes_s2 = [float(s2[i]) for i in range(1, 1 + len(criteria))]\n",
    "\n",
    "    return criteria, weights, notes_s1, notes_s2\n",
    "\n",
    "subjects, weights, sol1, sol2 = load_first_two_solutions_27crit(\"data27crit.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82d85f",
   "metadata": {},
   "source": [
    "2. Explication mixte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101f07d",
   "metadata": {},
   "source": [
    "Nous testons directement l’existence d’une explication mixte, combinant des trade-offs de type (1–m) et (m–1), pour une comparaison donnée. Aucune hypothèse préalable n’est faite sur la validité de la comparaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78758d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects, weights, sol1, sol2 = load_first_two_solutions_27crit(\"data/data27crit.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "038efd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution 1 > solution 2\n",
      "OPTIMAL\n",
      "Groupe (1-m) : L'avantage a (+876.0) compense ['e']\n",
      "Groupe (1-m) : L'avantage h (+276.0) compense ['i', 'x']\n",
      "Groupe (1-m) : L'avantage j (+862.0) compense ['r']\n",
      "Groupe (1-m) : L'avantage m (+524.0) compense ['A']\n",
      "Groupe (1-m) : L'avantage n (+968.0) compense ['l', 'p']\n",
      "Groupe (1-m) : L'avantage o (+380.0) compense ['g']\n",
      "Groupe (m-1) : Les avantages ['u'] (+314.0) compensent f (-224.00000000000006)\n",
      "Groupe (m-1) : Les avantages ['c'] (+778.0) compensent k (-496.0)\n",
      "Groupe (m-1) : Les avantages ['d'] (+926.0) compensent q (-513.9999999999999)\n",
      "Groupe (m-1) : Les avantages ['s'] (+844.0) compensent t (-826.0)\n",
      "Groupe (m-1) : Les avantages ['b'] (+876.0) compensent v (-348.0)\n",
      "Groupe (m-1) : Les avantages ['z'] (+906.0) compensent w (-582.0)\n"
     ]
    }
   ],
   "source": [
    "status, explanation = explication_hybride(sol1, sol2, weights, subjects)\n",
    "print(\"solution 1 > solution 2\")\n",
    "print(status)\n",
    "for e in explanation:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1627120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution 2 > solution 1\n",
      "INFEASIBLE\n",
      "Aucune explication mixte possible.\n"
     ]
    }
   ],
   "source": [
    "status, explanation = explication_hybride(sol2, sol1, weights, subjects)\n",
    "print(\"solution 2 > solution 1\")\n",
    "print(status)\n",
    "\n",
    "if explanation is not None:\n",
    "    for e in explanation:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Aucune explication mixte possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ad6d1",
   "metadata": {},
   "source": [
    "Interprétation des résultats\n",
    "\n",
    "Pour la comparaison solution 1 > solution 2, le solveur retourne le statut OPTIMAL, ce qui indique l’existence d’une explication mixte valide combinant des trade-offs de type (1–m) et (m–1).\n",
    "La supériorité de la solution 1 peut ainsi être justifiée par des compensations locales entre critères, sans utiliser de score global.\n",
    "\n",
    "En revanche, pour la comparaison inverse solution 2 > solution 1, le solveur retourne le statut INFEASIBLE.\n",
    "Cela constitue un certificat de non-existence d’explication dans le langage considéré : aucune combinaison de trade-offs autorisés ne permet de justifier cette supériorité.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
